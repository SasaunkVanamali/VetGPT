{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdccda25-bcaa-41e1-a492-03f2b569d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c907fdf6-0dda-4de6-895b-fbf02ed8abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the specified local path\n",
    "df = pd.read_csv(r\"..\\data\\merged_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bd7cce-8f4d-4478-9a95-c8312e798b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tokenizer(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []  \n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text.lower())\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "token_counts = Counter()\n",
    "for text in df['Title']:\n",
    "    tokens = basic_tokenizer(text)\n",
    "    token_counts.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c39393-e35a-444a-b3f9-71bcf551fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {word: i+1 for i, (word, _) in enumerate(token_counts.items())} \n",
    "vocab['<pad>'] = 0\n",
    "vocab['<unk>'] = len(vocab)\n",
    "\n",
    "\n",
    "def encode(text, vocab=vocab):\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in basic_tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3b1e05-d86c-457b-8b37-8680fb1fc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeterinaryDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_len=128):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx]['Title']  \n",
    "        input_ids = encode(text, self.vocab)[:self.max_len]\n",
    "        input_ids += [0] * (self.max_len - len(input_ids))  \n",
    "        return torch.tensor(input_ids, dtype=torch.long)\n",
    "\n",
    "dataset = VeterinaryDataset(df, vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43bcec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80cbe6d7-1e63-4d08-ba75-db2a16873f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VetGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len=128, n_layers=4, n_heads=8, d_model=256, d_ff=512):\n",
    "        super(VetGPT, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model, n_heads, d_ff) for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "model = VetGPT(vocab_size=vocab_size) \n",
    "\n",
    "\n",
    "#GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc71262d-c734-4437-b4b0-c1afa3997229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 4.8480\n",
      "Epoch 2/5, Loss: 2.7975\n",
      "Epoch 3/5, Loss: 1.7868\n",
      "Epoch 4/5, Loss: 1.1588\n",
      "Epoch 5/5, Loss: 0.7480\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 5e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding index in loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch  # Keep on CPU\n",
    "        targets = inputs.clone()  # Clone for target prediction\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Keep outputs on CPU\n",
    "        outputs = outputs.view(-1, vocab_size)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773228ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019beeb6-53b4-404f-8958-09f89b2d1190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Asthma in Cats\thttps://veterinarypartner.vin.com/default.aspx?pid=19239&catId=254055&id=4951536\tIf your cat needs to open its mouth to breathe or if its abdomen moves excessively as it breathes (and it is not purring), then it may be suffering from feline asthma. Asthma is a recurring respiratory compromise that occurs when the lung airways constrict either spontaneously or in response to stimuli that normally should not cause a reaction.\n"
     ]
    }
   ],
   "source": [
    "def search_dataset_fuzzy(df, query, threshold=70):\n",
    "\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        title = row.get('Title', '')\n",
    "        description = row.get('Field', '')\n",
    "        \n",
    "        title_score = fuzz.partial_ratio(query_lower, str(title).lower())\n",
    "        description_score = fuzz.partial_ratio(query_lower, str(description).lower())\n",
    "        \n",
    "\n",
    "        if title_score >= threshold or description_score >= threshold:\n",
    "            url = row.get('Title_URL', 'No URL available')\n",
    "            results.append((title, url, description, max(title_score, description_score)))\n",
    "\n",
    "\n",
    "    results = sorted(results, key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    if results:\n",
    "        best_match = results[0]\n",
    "        return f\"{best_match[0]}\\t{best_match[1]}\\t{best_match[2]}\"\n",
    "    else:\n",
    "        return \"No relevant entries found.\"\n",
    "\n",
    "query = input(\"Ask a Veterinary Question: \")\n",
    "response = search_dataset_fuzzy(df, query)\n",
    "print(\"Response:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
